[{"authors":null,"categories":null,"content":"I am a senior year undergraduate student at BITS Pilani (Goa Campus), pursuing a major in Electrical \u0026amp; Electronics engineering. I spend most of my time dabbling in research related to computational models of language. Currently, I am working as a Research Assistant at MIDAS-IIITD, and as a Project Assistant at the Cognitive Neuroscience Lab at BITS Goa. I also play around with competitive Data Science and am currently a Competitions Expert on Kaggle.\nI am also active in the student community: leading the students' Language Research Group (LRG) and being a core member at the Society for Artificial Intelligence and Deep Learning (SAiDL) at BITS Goa. Apart from the above mentioned technical interests, I also share a keen interest towards Social Sciences, Eco-criticism, Electronic Music \u0026amp; Table Tennis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://rajaswa.github.io/author/rajaswa-patil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rajaswa-patil/","section":"authors","summary":"I am a senior year undergraduate student at BITS Pilani (Goa Campus), pursuing a major in Electrical \u0026amp; Electronics engineering. I spend most of my time dabbling in research related to computational models of language.","tags":null,"title":"Rajaswa Patil","type":"authors"},{"authors":["Rajaswa Patil","Jasleen Dhillon","Siddhant Mahurkar","Saumitra Kulkarni","Manav Malhotra","Veeky Baths"],"categories":null,"content":"","date":1611945000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611945000,"objectID":"52b7732309e8b450dfa5406873395834","permalink":"https://rajaswa.github.io/publication/vyakarana-2021/","publishdate":"2021-01-30T00:00:00+05:30","relpermalink":"/publication/vyakarana-2021/","section":"publication","summary":"While there has been significant progress towards developing NLU datasets and benchmarks for Indic languages, syntactic evaluation has been relatively less explored. Unlike English, Indic languages have a rich morphosyntax, grammatical genders, free linear word-order, and a highly inflectional morphology. In this paper, we introduce *Vyākarana*: a benchmark dataset of Colorless Green sentences in Indic languages for syntactic testing of multilingual language models. We use the dataset to probe four multilingual language models: mBERT, DistilmBERT, XLM-R, and IndicBERT for syntax in Indic languages. In our experiments, we report the results of layer-wise probing for four syntax-related tasks: PoS Tagging, Syntax Tree-depth Prediction, Grammatical Case Marking, and Subject-Verb Agreement. Our results show that the language models trained with Indic languages exclusively do not capture syntax as efficiently as the other highly multilingual language models.","tags":["Indic-NLP","Syntax"],"title":"Vyākarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages","type":"publication"},{"authors":["Rajaswa Patil","Yaman Kumar Singla","Rajiv Ratn Shah","Mika Hama","Roger Zimmermann"],"categories":null,"content":"","date":1609439400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609439400,"objectID":"bd9e82500f8a29ee9d5ed8ceffbb4bc5","permalink":"https://rajaswa.github.io/publication/spoken_discourse_coherence-2021/","publishdate":"2021-01-01T00:00:00+05:30","relpermalink":"/publication/spoken_discourse_coherence-2021/","section":"publication","summary":"While there has been significant progress towards modelling coherence in written discourse, the work in modelling spoken discourse coherence has been quite limited. Unlike the coherence in text, coherence in spoken discourse is also dependent on the prosodic and acoustic patterns in speech. In this paper, we model coherence in spoken discourse with audio-based coherence models. We perform experiments with four coherence-related tasks with spoken discourses. In our experiments, we evaluate machine-generated speech against the speech delivered by expert human speakers. We also compare the spoken discourses generated by human language learners of varying language proficiency levels. Our results show that incorporating the audio modality along with the text benefits the coherence models in performing downstream coherence related tasks with spoken discourses.","tags":["NLP","Speech"],"title":"Towards Modelling Coherence in Spoken Discourse","type":"publication"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be participating in a round table discussion at the International CCCP Symposium 2020. I\u0026rsquo;ll be talking about the current state of data and resources in the study of Syntactic Processing!\n","date":1607212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607212800,"objectID":"525665083a70758ea5ec4a7ab9e3debb","permalink":"https://rajaswa.github.io/news/ibrainroundtable/","publishdate":"2020-12-06T00:00:00Z","relpermalink":"/news/ibrainroundtable/","section":"news","summary":"I\u0026rsquo;ll be participating in a round table discussion at the International CCCP Symposium 2020. I\u0026rsquo;ll be talking about the current state of data and resources in the study of Syntactic Processing!","tags":null,"title":"I'll be participating in a round table discussion at the International CCCP Symposium 2020!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection! Shoot me an e-mail or catch me at the conference socials!\nThis conference visit is funded by the Cognitive Neuroscience Lab at BITS Goa.\n","date":1607126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607126400,"objectID":"128302e92f11e87e0c089e445661729b","permalink":"https://rajaswa.github.io/news/coling2020/","publishdate":"2020-12-05T00:00:00Z","relpermalink":"/news/coling2020/","section":"news","summary":"I\u0026rsquo;ll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection! Shoot me an e-mail or catch me at the conference socials!\nThis conference visit is funded by the Cognitive Neuroscience Lab at BITS Goa.","tags":null,"title":"I'll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection!","type":"news"},{"authors":["Rajaswa Patil","Somesh Singh","Swati Agarwal"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"af19c65db8acdb4040658ec5c51bcab3","permalink":"https://rajaswa.github.io/publication/semeval-propaganda-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-propaganda-2020/","section":"publication","summary":"Propaganda spreads the ideology and beliefs of like-minded people, brainwashing their audiences, and sometimes leading to violence. SemEval 2020 Task-11 aims to design automated systems for news propaganda detection. Task-11 consists of two sub-tasks, namely, Span Identification - given any news article, the system tags those specific fragments which contain at least one propaganda technique; and Technique Classification - correctly classify a given propagandist statement amongst 14 propaganda techniques. For sub-task 1, we use contextual embeddings extracted from pre-trained transformer models to represent the text data at various granularities and propose a multi-granularity knowledge sharing approach. For sub-task 2, we use an ensemble of BERT and logistic regression classifiers with linguistic features. Our results reveal that the linguistic features are the strong indicators for covering minority classes in a highly imbalanced dataset.","tags":["NLP","AI4SG","Social Computing","Information Retrieval"],"title":"BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning","type":"publication"},{"authors":["Rajaswa Patil","Veeky Baths"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"0a706038cb88bb531f6631dc4ad97aea","permalink":"https://rajaswa.github.io/publication/semeval-counterfactual-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-counterfactual-2020/","section":"publication","summary":"In this paper, we describe an approach for modelling causal reasoning in natural language by detecting counterfactuals in text using multi-head self-attention weights. We use pre-trained transformer models to extract contextual embeddings and self-attention weights from the text. We show the use of convolutional layers to extract task-specific features from these self-attention weights. Further, we describe a fine-tuning approach with a common base model for knowledge sharing between the two closely related sub-tasks for counterfactual detection. We analyze and compare the performance of various transformer models in our experiments. Finally, we perform a qualitative analysis with the multi-head self-attention weights to interpret our models’ dynamics.","tags":["NLP","Information Retrieval"],"title":"CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection","type":"publication"},{"authors":["Siddhant Mahurkar","Rajaswa Patil"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"d2a91774b7bad44c659dc1eb7d4ae81a","permalink":"https://rajaswa.github.io/publication/semeval-humor-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-humor-2020/","section":"publication","summary":"In this paper, we assess the ability of BERT and its derivative models (RoBERTa, DistilBERT, and ALBERT) for short-edits based humor grading. We test these models for humor grading and classification tasks on the Humicroedit and the FunLines dataset. We perform extensive experiments with these models to test their language modeling and generalization abilities via zero-shot inference and cross-dataset inference based approaches. Further, we also inspect the role of self-attention layers in humor-grading by performing a qualitative analysis over the self-attention weights from the final layer of the trained BERT model. Our experiments show that all the pre-trained BERT derivative models show significant generalization capabilities for humor-grading related tasks.","tags":["NLP"],"title":"LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading","type":"publication"},{"authors":null,"categories":null,"content":"\u0026ldquo;I have been shortlisted to attend the first Google Research AI Summer School (2020)! Shoot me an e-mail or catch me at the conference socials!\n","date":1597536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597536000,"objectID":"821400715dca2293b4a144d854b324ee","permalink":"https://rajaswa.github.io/news/googlesummerschool2020/","publishdate":"2020-08-16T00:00:00Z","relpermalink":"/news/googlesummerschool2020/","section":"news","summary":"\u0026ldquo;I have been shortlisted to attend the first Google Research AI Summer School (2020)! Shoot me an e-mail or catch me at the conference socials!","tags":null,"title":"I'll be attending the Google Research AI Summer School 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"70d6656fe6bbaea59cefb8a84bd25cad","permalink":"https://rajaswa.github.io/news/semevaltask5accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask5accept/","section":"news","summary":"Our paper CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Counterfactual Detection accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"ca6b19a7b316353f9d2ba67d42621275","permalink":"https://rajaswa.github.io/news/semevaltask7accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask7accept/","section":"news","summary":"Our paper LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Humor Grading accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"d9fe938dc21bb801fabba998ceadb074","permalink":"https://rajaswa.github.io/news/semevaltask11accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask11accept/","section":"news","summary":"Our paper BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Propaganda Detection accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be taking up the Teaching Assitantship duty for the Neuroscience \u0026amp; AI Reading Course at the Cognitive Neuroscience Lab at BITS Goa. We\u0026rsquo;ll be covering the following topics: Syntactic Processing, Grounded Language Learning, Models of Mental Lexicon Development, Neural Correlates of Discourse Coherence, and Brain Embeddings. Shoot me an e-mail to enroll in the course!\n","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591315200,"objectID":"3b707a46674eb3cf017b6e0c0f7d5df6","permalink":"https://rajaswa.github.io/news/neuroairc/","publishdate":"2020-06-05T00:00:00Z","relpermalink":"/news/neuroairc/","section":"news","summary":"I\u0026rsquo;ll be taking up the Teaching Assitantship duty for the Neuroscience \u0026amp; AI Reading Course at the Cognitive Neuroscience Lab at BITS Goa. We\u0026rsquo;ll be covering the following topics: Syntactic Processing, Grounded Language Learning, Models of Mental Lexicon Development, Neural Correlates of Discourse Coherence, and Brain Embeddings.","tags":null,"title":"Neuroscience \u0026 AI Reading Course starts at CNRL BITS Goa!","type":"news"},{"authors":["Rajaswa Patil","Siddhant Mahurkar"],"categories":null,"content":"","date":1576089000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576089000,"objectID":"97a43b49ee45dd2de71b81525aaebcfa","permalink":"https://rajaswa.github.io/publication/kedl-citta-2019/","publishdate":"2019-12-12T00:00:00+05:30","relpermalink":"/publication/kedl-citta-2019/","section":"publication","summary":"Most of the recommendation and search frameworks in Digital Libraries follow a keyword-based approach to resolve text-based search queries. Keyword-based methods usually fail to capture the semantic aspects of the user’s query and often lead to a misleading set of results. In this work, we propose an efficient and content-sentiment aware semantic recommendation framework, Citta. The framework is designed with the BERT language model. It is designed to retrieve semantically related reading recommendations with short input queries and shorter response times. We test the proposed framework on the CMU Book Summary Dataset and discuss the observed advantages and shortcomings of the framework.","tags":["NLP","Information Retrieval"],"title":"Citta: A Lite Semantic Recommendation Framework for Digital Libraries","type":"publication"},{"authors":["Ajay Subramanian","Rajaswa Patil","Veeky Baths"],"categories":null,"content":"","date":1576089000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576089000,"objectID":"e60e9dd094f8f8cd0fe3294c4ae4a18f","permalink":"https://rajaswa.github.io/publication/accs-word2brain2image-2019/","publishdate":"2019-12-12T00:00:00+05:30","relpermalink":"/publication/accs-word2brain2image-2019/","section":"publication","summary":"Recent work in cognitive neuroscience has aimed to better understand how the brain responds to external stimuli. Extensive study is being done to gauge the involvement of various regions of the brain in the processing of external stimuli. A study by Ostarek et al. has produced experimental evidence of the involvement of low-level visual representations in spoken word processing, using Continuous Flash Suppression (CFS). For example, hearing the word ‘car’ induces a visual representation of a car in extrastriate areas of the visual cortex that seems to have a spatial resolution of some kind. Though the structure of these areas of the brain has been extensively studied, research hasn’t really delved into the functional aspects. In this work, we aim to take this a step further by experimenting with generative models such as Variational Autoencoders (VAEs) (Kingma et al 2013) and Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) to generate images purely from the EEG signals induced by listening to spoken words of objects.","tags":["Cognitive Science","Neuroscience"],"title":"Word2Brain2Image: Visual Reconstruction from Spoken Word Representations","type":"publication"}]