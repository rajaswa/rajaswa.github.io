[{"authors":null,"categories":null,"content":"I am a Pre-doctoral Research Fellow at TCS Research, where I\u0026rsquo;m co-advised by Dr. Gautam Shroff, Dr. Lovekesh Vig, and Dr. Shirish Karande. My work broadly focuses on Program Synthesis from Natural Language.\nI completed my bachelor\u0026rsquo;s degree in Electrical \u0026amp; Electronics Engineering from BITS Pilani (Goa Campus). Previously, I had the opportunity of working at the Max Planck Institute for Human Cognitive and Brain Sciences, MIDAS-IIITD, Cognizer Inc, and Cognitive Neuroscience Lab at BITS Goa during my undergraduate studies. I also play around with competitive Data Science and am currently a Competitions Expert on Kaggle.\n Current \u0026amp; Past Affiliations  ","date":1627477200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1627477200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://rajaswa.github.io/author/rajaswa-patil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rajaswa-patil/","section":"authors","summary":"I am a Pre-doctoral Research Fellow at TCS Research, where I\u0026rsquo;m co-advised by Dr. Gautam Shroff, Dr. Lovekesh Vig, and Dr. Shirish Karande. My work broadly focuses on Program Synthesis from Natural Language.","tags":null,"title":"Rajaswa Patil","type":"authors"},{"authors":null,"categories":null,"content":"Our paper VyƒÅkarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages has been accpeted for presentation at the First Workshop on Multilingual Representation Learning at EMNLP 2021.\nYou can check out the code and dataset here!\n","date":1632528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632528000,"objectID":"502a1e6634ae021852a95d5f154f8b0f","permalink":"https://rajaswa.github.io/news/mrl2021accept/","publishdate":"2021-09-25T00:00:00Z","relpermalink":"/news/mrl2021accept/","section":"news","summary":"Our paper VyƒÅkarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages has been accpeted for presentation at the First Workshop on Multilingual Representation Learning at EMNLP 2021.\nYou can check out the code and dataset here!","tags":null,"title":"Long Paper accepted at MRL-EMNLP 2021!","type":"news"},{"authors":null,"categories":null,"content":"I will be serving as the member of the Program Committe for the First Workshop on Multilingual Representation Learning at EMNLP 2021.\n","date":1629849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629849600,"objectID":"f0c9556ccde43c7b7197ae371f5e3416","permalink":"https://rajaswa.github.io/news/mrl2021pc/","publishdate":"2021-08-25T00:00:00Z","relpermalink":"/news/mrl2021pc/","section":"news","summary":"I will be serving as the member of the Program Committe for the First Workshop on Multilingual Representation Learning at EMNLP 2021.","tags":null,"title":"I'll be serving as a PC member at the MRL 2021 workshop at EMNLP 2021","type":"news"},{"authors":null,"categories":null,"content":"Our paper DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature has been accpeted for presentation at the EMNLP 2021 conference.\nYou can check out the demo for the system here!\n","date":1629849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629849600,"objectID":"aa0987940ad0f62fc45c994c630d4dc4","permalink":"https://rajaswa.github.io/news/emnlp2021acept/","publishdate":"2021-08-25T00:00:00Z","relpermalink":"/news/emnlp2021acept/","section":"news","summary":"Our paper DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature has been accpeted for presentation at the EMNLP 2021 conference.\nYou can check out the demo for the system here!","tags":null,"title":"System Demonstration Paper accepted at EMNLP 2021!","type":"news"},{"authors":["Rajaswa Patil"],"categories":null,"content":"","date":1627477200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627477200,"objectID":"a1aea3c0922bf47fec4ba47cc463a440","permalink":"https://rajaswa.github.io/talk/2021_acm_ml_talk/","publishdate":"2021-07-28T14:00:00Z","relpermalink":"/talk/2021_acm_ml_talk/","section":"talk","summary":"ACM BITS Goa \"Getting Started with ML\"","tags":["ML"],"title":"ACM BITS Goa \"Getting Started with ML\" Talk 2021","type":"talk"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be giving a talk on \u0026ldquo;Getting Started with ML\u0026rdquo; at an ACM BITS Goa event! You can attend the talk on a YouTube livestream here on 28th July 7:30PM IST.\n","date":1627344000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627344000,"objectID":"e895759d4c3bc021aaa24dd8d6a50574","permalink":"https://rajaswa.github.io/news/acmml2021talk/","publishdate":"2021-07-27T00:00:00Z","relpermalink":"/news/acmml2021talk/","section":"news","summary":"I\u0026rsquo;ll be giving a talk on \u0026ldquo;Getting Started with ML\u0026rdquo; at an ACM BITS Goa event! You can attend the talk on a YouTube livestream here on 28th July 7:30PM IST.","tags":null,"title":"I'll be giving a talk on Getting Started with ML at an ACM BITS Goa event!","type":"news"},{"authors":null,"categories":null,"content":"I have joined TCS Research as a Pre-doctoral Research Fellow, where I\u0026rsquo;ll be co-advised by Dr. Lovekesh Vig and Dr. Gautam Shroff. My work will broadly focus on \u0026ldquo;Program Synthesis from Natural Language\u0026rdquo;.\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"9335eb30fba461efa8259f7389ccb894","permalink":"https://rajaswa.github.io/news/tcsresearchpredoc/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/news/tcsresearchpredoc/","section":"news","summary":"I have joined TCS Research as a Pre-doctoral Research Fellow, where I\u0026rsquo;ll be co-advised by Dr. Lovekesh Vig and Dr. Gautam Shroff. My work will broadly focus on \u0026ldquo;Program Synthesis from Natural Language\u0026rdquo;.","tags":null,"title":"I have joined TCS Research as a Pre-doctoral Research Fellow!","type":"news"},{"authors":null,"categories":null,"content":"Table of Contents  About Setup Data Usage  Launch the app Train Mode Analysis Mode   Citation     About DRIFT is a tool for Diachronic Analysis of Scientific Literature. The application offers user-friendly and customizable utilities for two modes: Training and Analysis. Currently, the application supports customizable training of diachronic word embeddings with the TWEC model. The application supports a variety of analysis methods to monitor trends and patterns of development in scientific literature:\n Word Cloud Productivity/Frequency Plot Acceleration Plot Semantic Drift Tracking Clusters Acceleration Heatmap Track Trends with Similarity Keyword Visualisation LDA Topic Modelling  NOTE: The online demo is hosted using Streamlit sharing. This is a single-instance single-process deployment, accessible to all the visitors publicly (avoid sharing sensitive information on the demo). Hence, it is highly recommended to use your own independent local deployment of the application for a seamless and private experience. One can alternatively fork this repository and host it using Streamlit sharing.\nWe would love to know about any issues found on this repository. Please submit an issue for any query, or contact us here. If you use this application in your work, you can cite this repository and the paper here.\n Setup Clone the repository:\ngit clone https://github.com/rajaswa/DRIFT.git\rcd DRIFT\r Install the requirements:\nmake install_req\r Data The dataset we have used for our demo, and the analysis in the paper was scraped using the arXiv API (see script). We scraped papers from the cs.CL subject. This dataset is available here.\nThe user can upload their own dataset to the DRIFT application. The unprocessed dataset should be present in the following format (as a JSON file):\n{\r\u0026lt;year_1\u0026gt;:[\r\u0026lt;paper_1\u0026gt;,\r\u0026lt;paper_2\u0026gt;,\r...\r],\r\u0026lt;year_2\u0026gt;:[\r\u0026lt;paper_1\u0026gt;,\r\u0026lt;paper_2\u0026gt;,\r...\r],\r...,\r\u0026lt;year_m\u0026gt;:[\r\u0026lt;paper_1\u0026gt;,\r\u0026lt;paper_2\u0026gt;,\r...\r],\r}\r where year_x is a string (e.g., \u0026quot;1998\u0026quot;), and paper_x is a dictionary. An example is given below:\n{\r\u0026quot;url\u0026quot;:\u0026quot;http://arxiv.org/abs/cs/9809020v1\u0026quot;,\r\u0026quot;date\u0026quot;:\u0026quot;1998-09-15 23:49:32+00:00\u0026quot;,\r\u0026quot;title\u0026quot;:\u0026quot;Linear Segmentation and Segment Significance\u0026quot;,\r\u0026quot;authors\u0026quot;:[\r\u0026quot;Min-Yen Kan\u0026quot;,\r\u0026quot;Judith L. Klavans\u0026quot;,\r\u0026quot;Kathleen R. McKeown\u0026quot;\r],\r\u0026quot;abstract\u0026quot;:\u0026quot;We present a new method for discovering a segmental discourse structure of a\\ndocument while categorizing segment function. We demonstrate how retrieval of\\nnoun phrases and pronominal forms, along with a zero-sum weighting scheme,\\ndetermines topicalized segmentation. Futhermore, we use term distribution to\\naid in identifying the role that the segment performs in the document. Finally,\\nwe present results of evaluation in terms of precision and recall which surpass\\nearlier approaches.\u0026quot;,\r\u0026quot;journal ref\u0026quot;:\u0026quot;Proceedings of 6th International Workshop of Very Large Corpora\\n (WVLC-6), Montreal, Quebec, Canada: Aug. 1998. pp. 197-205\u0026quot;,\r\u0026quot;category\u0026quot;:\u0026quot;cs.CL\u0026quot;\r}\r The only important key is \u0026quot;abstract\u0026quot;, which has the raw text. The user can name this key differently. See the Training section below for more details.\n Usage Launch the app To launch the app, run the following command from the terminal:\nstreamlit run app.py\r Train Mode Preprocesing The preprocessing stage takes a JSON file structured as shown in the Data section. They key for raw text is provided on which preprocessing takes place. During the preprocessing of the text, year-wise text files are created in a desired directory. During the preprocessing:\n All html tags are removed from the text. Contractions are replaced (e.g. \u0026lsquo;don\u0026rsquo;t\u0026rsquo; is converted to \u0026lsquo;do not\u0026rsquo;) Punctuations, non-ascii characters, stopwords are removed. All verbs are lemmatized.  After this, each processed text is stored in the respective year file separated by a new-line, along with all the data in a single file as compass.txt\nTraining The training mode uses the path where the processed text files are stored, and trains the TWEC model on the given text. The TWEC model trains a Word2Vec model on compass.txt and then the respective time-slices are trained on this model to get corresponding word vectors. In the sidebar, we provide several options like - whether to use Skipgram over CBOW, number of dynamic iterations for training, number of static iterations for training, negative sampling, etc. After training, we store the models at the specified path, which are used later in the analysis.\nAnalysis Mode Word Cloud A word cloud, or tag cloud, is a textual data visualization which allows anyone to see in a single glance the words which have the highest frequency within a given body of text. Word clouds are typically used as a tool for processing, analyzing and disseminating qualitative sentiment data.\nReferences:\n Word Cloud Explorer: Text Analytics based on Word Clouds wordcloud Package Free Word Cloud Generator  Productivity/Frequency Plot Our main reference for this method is this paper. In short, this paper uses normalized term frequency and term producitvity as their measures.\n Term Frequency: This is the normalized frequency of a given term in a given year. Term Productivity: This is a measure of the ability of the concept to produce new multi-word terms. In our case we use bigrams. For each year y and single-word term t, and associated n multi-word terms m, the productivity is given by the entropy:  Based on these two measures, they hypothesize three kinds of terms:\n Growing Terms: Those which have increasing frequency and productivity in the recent years. Consolidated Terms: Those that are growing in frequency, but not in productivity. Terms in Decline: Those which have reached an upper bound of productivity and are being used less in terms of frequency.  Then, they perform clustering of the terms based on their frequency and productivity curves over the years to test their hypothesis. They find that the clusters formed show similar trends as expected.\nNOTE: They also evaluate quality of their clusters using pseudo-labels, but we do not use any automated labels here. They also try with and without double-counting multi-word terms, but we stick to double-counting. They suggest it is more explanable.\nAcceleration Plot This plot is based on the word-pair acceleration over time. Our inspiration for this method is this paper. Acceleration is a metric which calculates how quickly the word embeddings for a pair of word get close together or farther apart. If they are getting closer together, it means these two terms have started appearing more frequently in similar contexts, which leads to similar embeddings. In the paper, it is described as:\nBelow, we display the top few pairs between the given start and end year in dataframe, then one can select years and then select word-pairs in the plot parameters expander. A reduced dimension plot is displayed.\nNOTE: They suggest using skip-gram method over CBOW for the model. They use t-SNE representation to view the embeddings. But their way of aligning the embeddings is different. They also use some stability measure to find the best Word2Vec model. The also use Word2Phrase which we are planning to add soon.\nSemantic Drift This plot represents the change in meaning of a word over time. This shift is represented on a 2-dimensional representation of the embedding space. To find the drift of a word, we calculate the distance between the embeddings of the word in the final year and in the initial year. We find the drift for all words and sort them in descending order to find the most drifted words. We give an option to use one of two distance metrics: Euclidean Distance and Cosine Distance.\nWe plot top-K (sim.) most similar words around the two representations of the selected word.\nIn the Plot Parameters expander, the user can select the range of years over which the drift will be computed. He/She can also select the dimensionality reduction method for plotting the embeddings.\nBelow the graph, we provide a list of most drifted words (from the top-K keywords). The user can also choose a custom word.\nTracking Clusters Word meanings change over time. They come closer or drift apart. In a certain year, words are clumped together, i.e., they belong to one cluster. But over time, clusters can break into two/coalesce together to form one. Unlike the previous module which tracks movement of one word at a time, here, we track the movement of clusters.\nWe plot the formed clusters for all the years lying in the selected range of years. NOTE: We give an option to use one of two libraries for clustering: sklearn or faiss. faiss' KMeans implementation is around 10 times faster than sklearn\u0026rsquo;s.\nAcceleration Heatmap This plot is based on the word-pair acceleration over time. Our inspiration for this method is this paper. Acceleration is a metric which calculates how quickly the word embeddings for a pair of word get close together or farther apart. If they are getting closer together, it means these two terms have started appearing more frequently in similar contexts, which leads to similar embeddings. In the paper, it is described as:\nFor all the selected keywords, we display a heatmap, where the brightness of the colour determines the value of the acceleration between that pair, i.e., the brightness is directly proportional to the acceleration value.\nNOTE: They suggest using skip-gram method over CBOW for the model.\nTrack Trends with Similarity In this method, we wish to chart the trajectory of a word/topic from year 1 to year 2.\nTo accomplish this, we allow the user to pick a word from year 1. At the same time, we ask the user to provide the desired stride. We search for the most similar word in the next stride years. We keep doing this iteratively till we reach year 2, updating the word at each step.\nThe user has to select a word and click on Generate Dataframe. This gives a list of most similar words in the next stride years. The user can now iteratively select the next word from the drop-down till the final year is reached.\nKeyword Visualisation Here, we use the YAKE Keyword Extraction method to extract keywords. You can read more about YAKE here.\nIn our code, we use an open source implementation of YAKE.\nNOTE: Yake returns scores which are indirectly proportional to the keyword importance. Hence, we do the following to report the final scores:\nLDA Topic Modelling Latent Dirichlet Allocation is a generative probabilistic model for an assortment of documents, generally used for topic modelling and extraction. LDA clusters the text data into imaginary topics.\nEvery topic can be represented as a probability distribution over ngrams and every document can be represented as a probability distribution over these generated topics.\nWe train LDA on a corpus where each document contains the abstracts of a particular year. We express every year as a probability distribution of topics.\nIn the first bar graph, we show how a year can be decomposed into topics. The graphs below the first one show a decomposition of the relevant topics.\nCitation You can cite our work as:\n@misc{sharma2021drift,\rtitle={DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature}, author={Abheesht Sharma and Gunjan Chhablani and Harshit Pandey and Rajaswa Patil},\ryear={2021},\reprint={2107.01198},\rarchivePrefix={arXiv},\rprimaryClass={cs.CL}\r}\r OR\nSharma, A., Chhablani, G., Pandey, H., \u0026amp; Patil, R. (2021). DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature.\r ","date":1625011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625011200,"objectID":"ab78e47c8bfec5c2915c6205fed056a5","permalink":"https://rajaswa.github.io/project/drift/","publishdate":"2021-06-30T00:00:00Z","relpermalink":"/project/drift/","section":"project","summary":"DRIFT is a tool for Diachronic Analysis of Scientific Literature. The application offers user-friendly and customizable utilities for two modes - Training and Analysis.","tags":["Demo","NLP"],"title":"DRIFT","type":"project"},{"authors":["Abheesht Sharma","Gunjan Chhablani","Harshit Pandey","Rajaswa Patil"],"categories":null,"content":"","date":1624991400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624991400,"objectID":"249a4bc13d32989904fd6e7c351cf490","permalink":"https://rajaswa.github.io/publication/drift-2021/","publishdate":"2021-06-30T00:00:00+05:30","relpermalink":"/publication/drift-2021/","section":"publication","summary":"In this work, we present to the NLP community, and to the wider research community as a whole, an application for the diachronic analysis of research corpora. We open source an easy-to-use tool coined: DRIFT, which allows researchers to track research trends and development over the years. The analysis methods are collated from well-cited research works, with a few of our own methods added for good measure. Succinctly put, some of the analysis methods are: keyword extraction, word clouds, predicting declining/stagnant/growing trends using Productivity, tracking bi-grams using Acceleration plots, finding the Semantic Drift of words, tracking trends using similarity, etc. To demonstrate the utility and efficacy of our tool, we perform a case study on the cs.CL corpus of the arXiv repository and draw inferences from the analysis methods. The toolkit and the associated code are available here: https://github.com/rajaswa/DRIFT/ .","tags":["NLP","Demo","Interpretability"],"title":"DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature","type":"publication"},{"authors":["Rajaswa Patil"],"categories":null,"content":"","date":1622206800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622206800,"objectID":"faec1ffbe476367396b7ce3450f19efa","permalink":"https://rajaswa.github.io/talk/2021_cte_thesis_talk/","publishdate":"2021-05-28T14:00:00Z","relpermalink":"/talk/2021_cte_thesis_talk/","section":"talk","summary":"A primer in the application process for research opportunities (for undergaduate/recently graduated students).","tags":["Academic","Job"],"title":"CTE Thesis Talk 2021","type":"talk"},{"authors":["Rajaswa Patil"],"categories":["Academic","Job"],"content":"Table of Contents  Overview üìô What is the task, what should we know? ü§î How do I secure the best possible research opportunity? ü§î  Searching for the right opportunities üîç Securing the right opportunities üíØ   Concluding thoughts üí≠    Overview üìô The aim of this post is to share my personal 1 experience and insights in the application process for research opportunities as an undergraduate student. The target audience of this post is the STEM undergraduate population in Indian universities (interested in research opportunities). The post will majorly focus on making the application process more organized and less tiring for the student. Any form of feedback is welcome! üòÉ\nWhat is the task, what should we know? ü§î Defining the task at hand, fortunately, seems quite straightforward: Securing research opportunties. But we do not define things loosely in research. Usually, this particular task has multiple aspects associated with it. Before you start analyzing and approaching various opportunities, it\u0026rsquo;s always helpful to assess things from your end:\n Img src: https://en.meming.world/   üë®‚Äçüî¨üî¨ The Work  What excites me the most? (Curiosity is the key to motivation!) What research topics would I like to work on? (You need NOT be proficient with them already!) What future prospects would I have once the work/duration is completed? (Endeavours in Research \u0026amp; Academia tend to be long and slow!)   üèÜüìù The Outcomes  What is the most important non-monetary outcome I should aim for? (Knowledge, Experience, and Networking!) What other non-monetary outcomes am I looking for? (Publications, patents, letter of recommendations, etc.) How is this going to affect my academics? (Thesis/project evaluation, simultaneous coursework \u0026amp; academic load, etc.)   üí∞üí∏ The Compensation  Do I want this to be a funded opportunity? (Usually, YES!) Am I in a position to secure a funded opportunity? (You ALWAYS are, the question is about the amount: budget and value!) How flexible should I be regarding this? (Don\u0026rsquo;t be too flexible, opportunities will always be there, know \u0026amp; protect your self-worth!)    Best career advice that I can give: Don\u0026#39;t ever attach yourself to a person, a place, a company, an organization or a project. Attach yourself to a mission, a calling, a purpose ONLY. That\u0026#39;s how you keep your power \u0026amp; your peace. It\u0026#39;s worked pretty well for me thus far.\n\u0026mdash; erica williams simon (@missewill) June 6, 2018 \rThere might be a couple more things, that you need to be sure about before approaching any opportunity (spend some time thinking about them!). Once you have noted all of them down, you can go ahead with the applications with a clear and confident mindset!\nHow do I secure the best possible research opportunity? ü§î The best possible answer (arguably) to this is:\n You do not! Aim for more, not for the best.\n As an undergraduate/recently graduated student, you\u0026rsquo;ll mostly find these two things to be true (over the time):\n Your expectations and interests keep changing! The job market (both academia \u0026amp; industry) is slightly stochastic!  Being a highly motivated student, coming from a competitive background, this is what this usually results in:  Img src: https://en.meming.world/  It is quite important to understand that it\u0026rsquo;s okay to wait behind the gates to an opportunity, not being let in. But its not okay, to be frustratingly stuck there. The key to beat the stochastic nature of the job market is:\n Increasing the quantity and scope of your applications!\n People usually use this strategy by \u0026ldquo;cold-mailing\u0026rdquo; a high number of researchers. Although it does seem to work, I do not think it\u0026rsquo;s the best way to apply for research opportunities 2. Once you are mentally prepared and well motivated for the applications, its time to explore the ocean of opportunities, and enjoy the process 3. This can be done by slowly \u0026amp; sincerely exploring your research community of interest, and networking. While the approaches listed below may seem to be implicit and slow, with a small investment of time üïí and effort üë®‚Äçüíª, they hold the potential to be a gold mine üåü‚õèÔ∏è for you!\nSearching for the right opportunities üîç There are multiple ways to build a steady source of news üì∞ and opportunities üì¢ in your field of interest. I might be missing out on a few of them as of now, but given below are the major ones that come to my mind. While these methods might not be as convenient as cold-mailing, they\u0026rsquo;ll reward you highly for your efforts by:\n Getting a reply on your queries and applications\n This is the first and most imporant part of research job applications, something which mass cold-mailing DOES NOT gurantee.\nOnline presence üíªüåê This is one of the most important things 4 to do as a researcher these days. Most of the opportunities are shared and secured via social media these days! Here are a few ways to build an online presence [click]  Follow leading researchers and organizations on social media (Twitter \u0026amp; LinkedIn) Follow various job-posting handles, Twitter lists, Discord forums, Subreddits, etc. If you do not where to look, start by following research leaders in your domain [^5]. Turn on notifications for important handles. If you are active enough on these platforms, you can declare your search for an opportunity on them (people do approach on their own)  \nMailing lists üì¢‚úâÔ∏è Subscribing to mailing lists gives you the first-hand access to the latest communication in the community. Here are some of the active mailing-lists that I currently know about:\nMachine Learning \u0026amp; AI ü§ñ [click]  ML-news UAI Connectionists   Psychology \u0026amp; Neuroscience üß† [click]  Lab Jobs Corpora-List CogSci The LINGUIST   Direct networking ü§ùüëã This is my personal favorite for an approach to search for opportunities. Not only it makes you feel involved in the community (bringing in the much needed motivation \u0026amp; confidence) but also provides one of the most assured way of securing an opportunity. Due to the global circumstances and the continous efforts of the global academic community, direct networking is becoming more and more easier each day.\nHere are a few ways to network efficiently in the scientific \u0026amp; academic community [click]  Attend conferences, summer schools, lectures, workshops, etc.  Most of these can be attended online Most of these have student waivers (free registration in many cases) Volunteer here to gain important experience and build a presence in the community   Enagage in scientific discourse on online platforms (Twitter, Reddit, etc.)  Researchers are exceptionally eager to reply here (and not on mail) This also helps you build online presence   Mail communication  This can be thought of as a personalized cold-mailing Ask researchers for resources: papers, code, books, course material, etc. Provide your feedback, constructive criticism, congratulations, etc. to authors of that paper you read      The key to impactful networking is not expecting any direct material returns from it and taking genuine interst in others' work üôÇ. The returns will come, as a reward for your continuous support to the community üéÅ.\n Securing the right opportunities üíØ Once you have a list of opportunites that you would like to apply for, its time to try your luck with them in the most organized and fun way possible.\nCracking the recruitment process üíº This basically comes down to convince the researcher that you\u0026rsquo;ll be making significant contributions to their work, which is why they should not miss out on hiring you. Usually, one needs to handle two things to do this:\n Carry some relevant skillset and experience (this can be overlooked for undergraduate students in most cases) Instilling trust in the researcher and their team that you will deliver as expected  While networking helps a lot with both these things, there are a few more things you can do to help your cause [click]  Prepare a short statement-of-purpose / draft e-mail  List your previous experience (work/academic/inudstrial) Point towards one of the researcher\u0026rsquo;s projects where you might be a good addition Explain how this opportunity is seriously important and relevant for you   List down a few ideas which you would like to work on (don\u0026rsquo;t worry about the correctness here, this is primiarily to show your sincere interest) Attach your updated personal website Attach your CV, transcripts, relevant project reports, etc. Show your interest and motivation at each stage of the recruitment process  Seek feedback at the end of each interview or assignment Ask questions and doubts (about the work or in general)     Oraganizing your applications üìÅ   Img src: https://simplysquaredaway.com/10-organizing-memes-laugh/  With increasing number of applications, it might get a bit trickier to organize them. Every application needs to be taken special care of. This inlcudes adapting your CV/Resume to the opportunity, preparing a SOP/cold-mail, preparing for the interviews, etc.\nHere are a few things that I follow to organize my applications [click]  Use a Kanban board to process your applications efficiently  I use Notion Kanban boards I use the following columns in my Kanban board:  Not Applied (set reminders üîî for the entires here, I ask my Google Assitant to do this for me) Applied (set follow-up reminders for this ‚úâÔ∏è) In Progress üïí Accepted ‚úîÔ∏è (you might have to choose from multiple offers eventually üòÅ) Rejected ‚ùå (you might have to revisit rejections while applying to similar opportunities in the future ü§î)     Use labels in your E-mail client to classify your application threads  I use separate labels for inudstry and academia applications I use separate labels for full-time and part-time/internship positions I assign a research topic label to each application     Tracking your applications ‚úâÔ∏è It is quite important to track your applications properly. Similar to organization, keeping a track of applications becomes difficult with increasing number of applications.\nHere are a few things that I follow to track my applications [click]  E-mail tracking  Students usually make the mistake of adding mail-trackers in their e-mails  This might block your e-mail, or divert it to spam folder of the reciever This might appear to be disrepsectful to the researcher   A better way of tracking here is using Google Analytics  Link your personal website to Google Analytics This lets you monitor a number of variables related to the beahvior and data of the website visitors List all your attachments in the mail via your website (i.e. CV, reports, code repositories, etc.) This allows you to know when and where was your e-mail read (and your website accessed) It also allows you to monitor the time spent on various web-pages on your website. Which gives a lot of information about what the recruiter has studied about you (which project, which paper, which course, etc.)     E-mail follow-ups  Given that researchers are usually quite busy and recieve a high number of e-mails, it is a good idea to send them a follow-up e-mail (make sure you understand the difference between spamming and sending follow-ups) Set reminder to send follow-ups after a particular period of time (Ex: 7 days) I use the followupthen tool to schedule follow up mails   Sending enquiries to appropriate professionals  You should enquire about the status of your applications to the right person Given the busy schedule of the researchers, usually a separate professional handles this For academic labs you should contact the Lab managers and Ph.D. \u0026amp; Master\u0026rsquo;s students in the lab For industrial labs you should contact the HR manager or the recruiter It is always a good habit to CC the supervising researcher nonetheless, to ensure that they are in the loop and your queries are handled seriously by the concerned authority.     Handling rejections the right way ü§ó  Img src: https://simplysquaredaway.com/10-organizing-memes-laugh/  There is a good chance that you\u0026rsquo;ll face numerous rejections before landing the perfect opportunity.\nWhile it is natural to get demotivated with each rejection, there is a lot to be gained from them [click]  Make sure you thank the researcher and his team for their time and consideration Compulsorily seek feedback about why you could not make it, by asking the following:  Where have could you improved your application? (helps with other future applications) Will they consider you (and alert) for any possible future opportunity?   Ask for the possibility of staying in touch with the researcher\u0026rsquo;s work by attending their lectures, lab reading sessions, etc.   Handling setbacks and rejections is one of the most important expected qualities in a researcher. Just showing willingness to take this rejection positively can significantly help your future prospects with opportunities from the same organization or researcher.\nConcluding thoughts üí≠ The whole process of scientific research can be quite exhausting and tiring üò´. Applying to opportunities is just the first step here. One simply cannot afford to get exhausted during the application stage itself. It is always good to approach other senior researchers around you, seeking help, discussing your thoughts, joys and frustrations. During your undergraduate studies, your seniors in the college or university can be approached. On the surface, the scientific community might seem to be inapproachable, busy, and arrogant. But once you explore the community, you\u0026rsquo;ll find them to be approachable and highly social \u0026amp; helping! üòä\n Do not hesitate, know your worth, know your potential. Support the community ‚ù§Ô∏è\n I would be really glad to know if this helped somebody land a research opportunity (drop me an e-mail if it did!). Any form of feedback on this post can be provided to me via e-mail or anonymously through this form.\n  This might not generalize perfectly across all the disciplines, demographies, and backgrounds. \u0026#x21a9;\u0026#xfe0e;\n I do not advocate against cold-mailing (in-fact its one of the beautiful tools in academic research. I advocate against \u0026ldquo;mass cold-mailing\u0026rdquo; specifically.) \u0026#x21a9;\u0026#xfe0e;\n I personally do not find cold-mailing enjoyable. \u0026#x21a9;\u0026#xfe0e;\n If not the most important. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1621987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621987200,"objectID":"392656818704e450fa4fe39d1685d443","permalink":"https://rajaswa.github.io/post/undergraduate_research_opportunity_applications/","publishdate":"2021-05-26T00:00:00Z","relpermalink":"/post/undergraduate_research_opportunity_applications/","section":"post","summary":"A primer in the application process for research opportunities (for undergaduate/recently graduated students) üßë‚Äçüî¨.","tags":["Academic","Job"],"title":"The Pursuit of Happiness - Undergraduate Research üßë‚Äçüî¨","type":"post"},{"authors":null,"categories":null,"content":"Our paper VyƒÅkarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages has been accpeted for presentation at the ACL-IJCNLP Student Research Workshop, 2021.\nThis work was funded by the Cognitive Neuroscience Lab at BITS Goa, and mentored by Prof. Greg Durrett, UT Austin during the pre-submission mentoring stage at the workshop.\n","date":1620950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620950400,"objectID":"bbc2d5be5a56cc8a30ffed0b461b7266","permalink":"https://rajaswa.github.io/news/aclsrw2021acept/","publishdate":"2021-05-14T00:00:00Z","relpermalink":"/news/aclsrw2021acept/","section":"news","summary":"Our paper VyƒÅkarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages has been accpeted for presentation at the ACL-IJCNLP Student Research Workshop, 2021.\nThis work was funded by the Cognitive Neuroscience Lab at BITS Goa, and mentored by Prof.","tags":null,"title":"Paper on Syntactic Evaluation in Indic languages accepted at ACL-IJCNLP SRW 2021!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be attending the Fifth Summer School on Statistical Methods for Linguistics and Psychology (Foundational methods in frequentist statistics track - class of 30 students), 6-10 September 2021. Shoot me an e-mail or catch me at the summer school!\nThis summer school is organized by Prof. Shravan Vasishth, University of Potsdam.\n","date":1620604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620604800,"objectID":"926031b370b32e9a0fa8a4316e81dba2","permalink":"https://rajaswa.github.io/news/smlp2021/","publishdate":"2021-05-10T00:00:00Z","relpermalink":"/news/smlp2021/","section":"news","summary":"I\u0026rsquo;ll be attending the Fifth Summer School on Statistical Methods for Linguistics and Psychology (Foundational methods in frequentist statistics track - class of 30 students), 6-10 September 2021. Shoot me an e-mail or catch me at the summer school!","tags":null,"title":"I'll be attending the Fifth Summer School on Statistical Methods for Linguistics and Psychology, 6-10 September 2021!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be contributing to a tutorial on Transformer models for NLP at the Neuromatch DL Summer School. This lecture will be taught by Prof. He He, NYU.\nDo sign-up for the summer school if interested in an Introduction to Deep Learning!\n","date":1620604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620604800,"objectID":"0987b8949cdf6e70880d86c2b3b6f173","permalink":"https://rajaswa.github.io/news/neuromatch2021/","publishdate":"2021-05-10T00:00:00Z","relpermalink":"/news/neuromatch2021/","section":"news","summary":"I\u0026rsquo;ll be contributing to a tutorial on Transformer models for NLP at the Neuromatch DL Summer School. This lecture will be taught by Prof. He He, NYU.\nDo sign-up for the summer school if interested in an Introduction to Deep Learning!","tags":null,"title":"I'll be contributing to a tutorial on Transformer models at Neuromatch DL Summer School!","type":"news"},{"authors":null,"categories":null,"content":"Table of Contents  Key Contributions  Feedback Transformer Implementation Solving COGS with Feedback Transformer Sequence Copy \u0026amp; Reverse Task   Citations Contact    My final project submission for the Meta Learning course at BITS Goa (conducted by TCS Research \u0026amp; BITS Goa). The project is based on the Feedback Transformer paper. The paper introduces a feedback mechanism in transformer models by adding a recurrent memory-attention based approach. This helps the transformer model in:\n Accessing higher level (layers) representations Maintaining a belief state Perform a learnable wieghted combined top-down and bottom-up processing Decrease compute memory-consumption at inference  The project can be run as a colab notebook  , where the approach given in the paper can be understood in more detail through experimentation. The experiments' Tensorboard logs and a video explanation for the notebook can be found here.\nKey Contributions The key contributions of this project can be listed as follows:\n Implementing and Open-sourcing a modular customizable Feedback Transformer Model in PyTorch Experimenting the Feedback Transformer Model with COGS Benchmark (Compositional Generalization) Implementing the Sequence Copy \u0026amp; Reverse Task from the original Feedback Transformer Paper  Feedback Transformer Implementation The Feedback Transformer Model has been implemented as PyTorch model class in the given notebook. You can adjust the various hyperparameters and turn the feedback ON/OFF in the Encoder and Decoder of the Model independently. Use the model in the following manner:\nmodel = FeedbackTransformerModel(\rencoder_feedback = False, # Disable Feedback Mehancism in the Encoder\rdecoder_feedback = True, # Enable Feedback Mehancism in the Decoder\rmemory_context = 8, # How long to look in the past for Memory-attention\rinput_vocab_size = 800, # Input Vocabulary Size\routput_vocab_size = 800, # Output Vocabulary Size\rd_model = 128, # Model Embedding Dimension\rnhead = 8, # Number of Heads in Multi-head Cross-attention and Memory-attention\rnum_layers = 4, # Number of Encoder and Decoder blocks\rdim_feedforward = 256, # Feedforward Dimension\rmax_seq_length = 1000, # Maximum Sequence Length in Data\rdropout = 0.1, # Model Dropout Probability PAD_IDX = 0, # PAD Token ID to Mask Padding tokens for Attention\ractivation = \u0026quot;gelu\u0026quot;, # Model Activation Function: \u0026quot;gelu\u0026quot; / \u0026quot;relu\u0026quot;\r)\r Solving COGS with Feedback Transformer The COGS Benchmark is a benchmark for evaluating compositional generalization \u0026amp; reasoning in natural language. The COGS task is that of mapping a natural language sentence to a lambda-expression based semantic logical form:\ninput_sentence = \u0026quot;The moose wanted to read .\u0026quot;\routput_logical_form = \u0026quot;* moose ( x _ 1 ) ; want . agent ( x _ 2 , x _ 1 ) AND want . xcomp ( x _ 2 , x _ 4 ) AND read . agent ( x _ 4 , x _ 1 )\u0026quot;\r This can be treated as a sequence-to-sequence semantic-parsing task. What makes this task challenging is its Generalization test set. The following points make it quite challenging:\n Novel (unseen in training) Combination of Familiar Primitives and Grammatical Roles Novel (unseen in training) Combination Modified Phrases and Grammatical Roles Deeper Recursion (results in longer sentences and deeper lingusitic strucutre i.e. parse tree) Verb Argument Structure Alternation Verb Class Alteration  You can check the COGS Paper for more details on the benchmark.\nThe COGS dataset can be loaded as a PyTorch-Lightning Module in the following manner:\ndatamodule = COGSDataModule(\rbatch_size=128, # Batch Size for Training num_workers=2, # Number of workers for Data Loading\ruse_100=False, # Whether to use single-exposure or hundred-exposures for pimitives in the training set\ruse_Gen=True # Whether to use normal test set or generaliztion test set\r)\r NOTE: The feedback transformer paper does not include this benchmark or any related task. This is the first attempt (to the best of my knowledge) to inspect the effect of incoroporating feedback and memory based architectural biases in solving compositional generalization problem in natural language.\nResults While the PyTorch-Lightning profiler and Tensorboard logger (included in the notebook) will give a detailed insights into the experiments, here are key metrics to report:\n   Encoder Feedback Decoder Feedback Num Parameters Validation Accuracy Generalization Accuracy Total Training time Mean Forward time Mean Backward time Inference time     False False 12.7k 69.5% 65.44% 193.43 s 22.58 ms 25.17 ms 20.08 ms   False True 12.3k 74.1% 70.86% 4441.7 s 645.08 ms 1039.30 ms 365.49 ms   True True 12.2k 74.4% 70.69% 7402.4 s 701.85 ms 1129.4 ms 404.65 ms    NOTE: The results are subject to change in hyperparameters and training settings. The above results are obtained from the current settings given in the notebook. The results can be increased significantly by training bigger models for longer times.\nDiscussion  The Validation accuracy (roughly equal to the Normal test accuracy) reflects the Expressivity of the models towards the COGS task  Access to higher level representations might help in semantic-parsing by allowing top-down processing In general, incorporating feedback gives the model more expressivity with lesser number of parameters   The Generalization test accuracy (usually lower than Validation and Normal test accuracy) reflects the Compositional Generalization capabilities of the models  This needs accurate inference on previously unseen novel linguistic structures and an ability to maintain a belief state for longer contexts On an absolute scale, incorporating feedback increases the Generalization test accuracies significantly High Expressivity can lead to poor Compositional Generalization in Vanilla Transformer models (as reported in the COGS Paper) The Vanilla Transformer model (no feedback) shows a 5.84% decrease in accuracy between the Validation and Generalization test set Enabling feedback in Decoder reduces the drop in Generalization accuracy to 4.37% Enabling feedback in Encoder further reduces the the drop in Generalization accuracy to 4.98%    Sequence Copy \u0026amp; Reverse Task The Sequence Copy \u0026amp; Reverse task is included in the Feedback Transformer paper as an Algorithmic task to test the role of memory in long-sequence processing. Since the official dataset is not publicly available, we generate the dataset synthetically.\nThe sequence copy \u0026amp; reverse dataset can be loaded as a PyTorch-Lightning Module in the following manner:\ndatamodule = SequenceCopyDataModule(\rbatch_size=64, # Batch Size for Training\rnum_workers=2, # Number of workers for Data Loading\rnum_samples_train=10000, # Number of samples to generate for training set\rnum_samples_eval=1000, # Number of samples to generate for validation and test set\rmax_length_train=10, # Sequence length in training samples\rmax_length_eval=50, # Sequence length in evaluation samples (Should be significantly longer to test for memory effect)\rreverse=True, # Whether to Copy the Input Sequence or Reverse the Input Sequence\r)\r NOTE: The ablation analysis for this task with Feedback Transformer is still in progress. One can still train the Feedback Transformer for this task using the last section of the project\u0026rsquo;s colab notebook.\nCitations If you use the code in this repository in any manner, cite the repository:\n@misc{patil2021-feedback-github,\rauthor = {Rajaswa Patil},\rtitle = {feedback-and-memory-in-transformers},\rmonth = apr,\ryear = 2021,\rpublisher = {Github},\rurl = \u0026quot;https://github.com/rajaswa/feedback-and-memory-in-transformers\u0026quot;\r}\r If you use the code for Feedback Transfomer or the Sequence Copy \u0026amp; Reverse task, cite the Feedback Transformer paper:\n@misc{fan2021addressing,\rtitle={Addressing Some Limitations of Transformers with Feedback Memory}, author={Angela Fan and Thibaut Lavril and Edouard Grave and Armand Joulin and Sainbayar Sukhbaatar},\ryear={2021},\reprint={2002.09402},\rarchivePrefix={arXiv},\rprimaryClass={cs.LG}\r}\r If you use the code from COGS Benchmark data processing and loading, cite the COGS paper:\n@inproceedings{kim-linzen-2020-cogs,\rtitle = \u0026quot;{COGS}: A Compositional Generalization Challenge Based on Semantic Interpretation\u0026quot;,\rauthor = \u0026quot;Kim, Najoung and\rLinzen, Tal\u0026quot;,\rbooktitle = \u0026quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\u0026quot;,\rmonth = nov,\ryear = \u0026quot;2020\u0026quot;,\raddress = \u0026quot;Online\u0026quot;,\rpublisher = \u0026quot;Association for Computational Linguistics\u0026quot;,\rurl = \u0026quot;https://www.aclweb.org/anthology/2020.emnlp-main.731\u0026quot;,\rdoi = \u0026quot;10.18653/v1/2020.emnlp-main.731\u0026quot;,\rpages = \u0026quot;9087--9105\u0026quot;,\rabstract = \u0026quot;Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96{--}99{\\%}), but generalization accuracy was substantially lower (16{--}35{\\%}) and showed high sensitivity to random seed (+-6{--}8{\\%}). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.\u0026quot;,\r}\r Contact Submit an issue here.\n","date":1619913600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619913600,"objectID":"eb07a5358eea9ed309346a630c4b83d1","permalink":"https://rajaswa.github.io/project/feedback-and-memory-in-transformers/","publishdate":"2021-05-02T00:00:00Z","relpermalink":"/project/feedback-and-memory-in-transformers/","section":"project","summary":"My final project submission for the Meta Learning course at BITS Goa (conducted by TCS Research \u0026 BITS Goa). The project is based on the Feedback Transformer paper.","tags":["Transformer","Generalization","Cognitive Science","NLP"],"title":"Feedback and Memory in Transformers","type":"project"},{"authors":["Arijit Gupta","Rajaswa Patil","Veeky Baths"],"categories":null,"content":"","date":1615573800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615573800,"objectID":"cba659156a4dd9094e08e8c110f5354e","permalink":"https://rajaswa.github.io/publication/lexical-development-children/","publishdate":"2021-03-13T00:00:00+05:30","relpermalink":"/publication/lexical-development-children/","section":"publication","summary":"Recent work has shown that distributed word representations can encode abstract semantic and syntactic information from child-directed speech. In this paper, we use diachronic distributed word representations to perform temporal modeling and analysis of lexical development in children. Unlike all previous work, we use temporally sliced speech corpus to learn distributed word representations of child and child-directed speech. Through our modeling experiments, we demonstrate the dynamics of growing lexical knowledge in children over time, as compared against a saturated level of lexical knowledge in child-directed adult speech. We also fit linear mixed-effects models with the rate of semantic change in the diachronic representations and word frequencies. This allows us to inspect the role of word frequencies towards lexical development in children. Further, we perform a qualitative analysis of the diachronic representations from our model, which reveals the categorization and word associations in the mental lexicon of children.","tags":["NLP","Cognitive Science","Psychology"],"title":"Using Diachronic Distributed Word Representations as Models of Lexical Development in Children","type":"publication"},{"authors":["Rajaswa Patil","Jasleen Dhillon","Siddhant Mahurkar","Saumitra Kulkarni","Manav Malhotra","Veeky Baths"],"categories":null,"content":"","date":1611945000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611945000,"objectID":"52b7732309e8b450dfa5406873395834","permalink":"https://rajaswa.github.io/publication/vyakarana-2021/","publishdate":"2021-01-30T00:00:00+05:30","relpermalink":"/publication/vyakarana-2021/","section":"publication","summary":"While there has been significant progress towards developing NLU resources for Indic languages, syntactic evaluation has been relatively less explored. Unlike English, Indic languages have rich morphosyntax, grammatical genders, free linear word-order, and highly inflectional morphology. In this paper, we introduce VyƒÅkarana: a benchmark of Colorless Green sentences in Indic languages for syntactic evaluation of multilingual language models. The benchmark comprises four syntax-related tasks: PoS Tagging, Syntax Tree-depth Prediction, Grammatical Case Marking, and Subject-Verb Agreement. We use the datasets from the evaluation tasks to probe five multilingual language models of varying architectures for syntax in Indic languages. Due to its prevalence, we also include a code-switching setting in our experiments. Our results show that the token-level and sentence-level representations from the Indic language models (IndicBERT and MuRIL) do not capture the syntax in Indic languages as efficiently as the other highly multilingual language models. Further, our layer-wise probing experiments reveal that while mBERT, DistilmBERT, and XLM-R localize the syntax in middle layers, the Indic language models do not show such syntactic localization.","tags":["Indic-NLP","Syntax","Interpretability"],"title":"VyƒÅkarana: A Colorless Green Benchmark for Syntactic Evaluation in Indic Languages","type":"publication"},{"authors":["Rajaswa Patil","Yaman Kumar Singla","Rajiv Ratn Shah","Mika Hama","Roger Zimmermann"],"categories":null,"content":"","date":1609439400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609439400,"objectID":"bd9e82500f8a29ee9d5ed8ceffbb4bc5","permalink":"https://rajaswa.github.io/publication/spoken_discourse_coherence-2021/","publishdate":"2021-01-01T00:00:00+05:30","relpermalink":"/publication/spoken_discourse_coherence-2021/","section":"publication","summary":"While there has been significant progress towards modelling coherence in written discourse, the work in modelling spoken discourse coherence has been quite limited. Unlike the coherence in text, coherence in spoken discourse is also dependent on the prosodic and acoustic patterns in speech. In this paper, we model coherence in spoken discourse with audio-based coherence models. We perform experiments with four coherence-related tasks with spoken discourses. In our experiments, we evaluate machine-generated speech against the speech delivered by expert human speakers. We also compare the spoken discourses generated by human language learners of varying language proficiency levels. Our results show that incorporating the audio modality along with the text benefits the coherence models in performing downstream coherence related tasks with spoken discourses.","tags":["NLP","Speech"],"title":"Towards Modelling Coherence in Spoken Discourse","type":"publication"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be participating in a round table discussion at the International CCCP Symposium 2020. I\u0026rsquo;ll be talking about the current state of data and resources in the study of Syntactic Processing!\n","date":1607212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607212800,"objectID":"712a7928169a6442d302b0887f0fa213","permalink":"https://rajaswa.github.io/news/ibrainroundtable/","publishdate":"2020-12-06T00:00:00Z","relpermalink":"/news/ibrainroundtable/","section":"news","summary":"I\u0026rsquo;ll be participating in a round table discussion at the International CCCP Symposium 2020. I\u0026rsquo;ll be talking about the current state of data and resources in the study of Syntactic Processing!","tags":null,"title":"I'll be participating in a round table discussion at the International CCCP Symposium 2020!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection! Shoot me an e-mail or catch me at the conference socials!\nThis conference visit is funded by the Cognitive Neuroscience Lab at BITS Goa.\n","date":1607126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607126400,"objectID":"e071527013b37ff998c9038225f82ca8","permalink":"https://rajaswa.github.io/news/coling2020/","publishdate":"2020-12-05T00:00:00Z","relpermalink":"/news/coling2020/","section":"news","summary":"I\u0026rsquo;ll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection! Shoot me an e-mail or catch me at the conference socials!\nThis conference visit is funded by the Cognitive Neuroscience Lab at BITS Goa.","tags":null,"title":"I'll be attending COLING 2020 to present our work on Humor Grading and Counterfactual Detection!","type":"news"},{"authors":["Rajaswa Patil","Somesh Singh","Swati Agarwal"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"af19c65db8acdb4040658ec5c51bcab3","permalink":"https://rajaswa.github.io/publication/semeval-propaganda-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-propaganda-2020/","section":"publication","summary":"Propaganda spreads the ideology and beliefs of like-minded people, brainwashing their audiences, and sometimes leading to violence. SemEval 2020 Task-11 aims to design automated systems for news propaganda detection. Task-11 consists of two sub-tasks, namely, Span Identification - given any news article, the system tags those specific fragments which contain at least one propaganda technique; and Technique Classification - correctly classify a given propagandist statement amongst 14 propaganda techniques. For sub-task 1, we use contextual embeddings extracted from pre-trained transformer models to represent the text data at various granularities and propose a multi-granularity knowledge sharing approach. For sub-task 2, we use an ensemble of BERT and logistic regression classifiers with linguistic features. Our results reveal that the linguistic features are the strong indicators for covering minority classes in a highly imbalanced dataset.","tags":["NLP","AI4SG","Social Computing","Information Retrieval"],"title":"BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning","type":"publication"},{"authors":["Rajaswa Patil","Veeky Baths"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"0a706038cb88bb531f6631dc4ad97aea","permalink":"https://rajaswa.github.io/publication/semeval-counterfactual-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-counterfactual-2020/","section":"publication","summary":"In this paper, we describe an approach for modelling causal reasoning in natural language by detecting counterfactuals in text using multi-head self-attention weights. We use pre-trained transformer models to extract contextual embeddings and self-attention weights from the text. We show the use of convolutional layers to extract task-specific features from these self-attention weights. Further, we describe a fine-tuning approach with a common base model for knowledge sharing between the two closely related sub-tasks for counterfactual detection. We analyze and compare the performance of various transformer models in our experiments. Finally, we perform a qualitative analysis with the multi-head self-attention weights to interpret our models‚Äô dynamics.","tags":["NLP","Information Retrieval"],"title":"CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection","type":"publication"},{"authors":["Siddhant Mahurkar","Rajaswa Patil"],"categories":null,"content":"","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"d2a91774b7bad44c659dc1eb7d4ae81a","permalink":"https://rajaswa.github.io/publication/semeval-humor-2020/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/publication/semeval-humor-2020/","section":"publication","summary":"In this paper, we assess the ability of BERT and its derivative models (RoBERTa, DistilBERT, and ALBERT) for short-edits based humor grading. We test these models for humor grading and classification tasks on the Humicroedit and the FunLines dataset. We perform extensive experiments with these models to test their language modeling and generalization abilities via zero-shot inference and cross-dataset inference based approaches. Further, we also inspect the role of self-attention layers in humor-grading by performing a qualitative analysis over the self-attention weights from the final layer of the trained BERT model. Our experiments show that all the pre-trained BERT derivative models show significant generalization capabilities for humor-grading related tasks.","tags":["NLP"],"title":"LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading","type":"publication"},{"authors":null,"categories":null,"content":"\u0026ldquo;I have been shortlisted to attend the first Google Research AI Summer School (2020)! Shoot me an e-mail or catch me at the conference socials!\n","date":1597536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597536000,"objectID":"656c0bc106aec13b9b72b21baadc734d","permalink":"https://rajaswa.github.io/news/googlesummerschool2020/","publishdate":"2020-08-16T00:00:00Z","relpermalink":"/news/googlesummerschool2020/","section":"news","summary":"\u0026ldquo;I have been shortlisted to attend the first Google Research AI Summer School (2020)! Shoot me an e-mail or catch me at the conference socials!","tags":null,"title":"I'll be attending the Google Research AI Summer School 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"472fb10cbe6b94507dc08eccd16e0f55","permalink":"https://rajaswa.github.io/news/semevaltask5accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask5accept/","section":"news","summary":"Our paper CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights Based Counterfactual Detection has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Counterfactual Detection accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"373ebaf5138d91cbdab9514885c8bbd1","permalink":"https://rajaswa.github.io/news/semevaltask7accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask7accept/","section":"news","summary":"Our paper LRG at SemEval-2020 Task 7: Assessing the Ability of BERT and Derivative Models to Perform Short-Edits Based Humor Grading has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Humor Grading accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"Our paper BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.\n","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593907200,"objectID":"6652eb10ef9675ba9c26eb12aafda76a","permalink":"https://rajaswa.github.io/news/semevaltask11accept/semevaltask11accept/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/news/semevaltask11accept/semevaltask11accept/","section":"news","summary":"Our paper BPGC at SemEval-2020 Task 11: Propaganda Detection in News Articles with Multi-Granularity Knowledge Sharing and Linguistic Features Based Ensemble Learning has been accpeted for publication at the International Workshop on Semantic Evaluation, 2020.","tags":null,"title":"Paper on Propaganda Detection accepted at SemEval 2020!","type":"news"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ll be taking up the Teaching Assitantship duty for the Neuroscience \u0026amp; AI Reading Course at the Cognitive Neuroscience Lab at BITS Goa. We\u0026rsquo;ll be covering the following topics: Syntactic Processing, Grounded Language Learning, Models of Mental Lexicon Development, Neural Correlates of Discourse Coherence, and Brain Embeddings. Shoot me an e-mail to enroll in the course!\n","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591315200,"objectID":"1b551df6c82c3fa1a0ce372411519709","permalink":"https://rajaswa.github.io/news/neuroairc/","publishdate":"2020-06-05T00:00:00Z","relpermalink":"/news/neuroairc/","section":"news","summary":"I\u0026rsquo;ll be taking up the Teaching Assitantship duty for the Neuroscience \u0026amp; AI Reading Course at the Cognitive Neuroscience Lab at BITS Goa. We\u0026rsquo;ll be covering the following topics: Syntactic Processing, Grounded Language Learning, Models of Mental Lexicon Development, Neural Correlates of Discourse Coherence, and Brain Embeddings.","tags":null,"title":"Neuroscience \u0026 AI Reading Course starts at CNRL BITS Goa!","type":"news"},{"authors":["Rajaswa Patil","Siddhant Mahurkar"],"categories":null,"content":"","date":1576089000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576089000,"objectID":"97a43b49ee45dd2de71b81525aaebcfa","permalink":"https://rajaswa.github.io/publication/kedl-citta-2019/","publishdate":"2019-12-12T00:00:00+05:30","relpermalink":"/publication/kedl-citta-2019/","section":"publication","summary":"Most of the recommendation and search frameworks in Digital Libraries follow a keyword-based approach to resolve text-based search queries. Keyword-based methods usually fail to capture the semantic aspects of the user‚Äôs query and often lead to a misleading set of results. In this work, we propose an efficient and content-sentiment aware semantic recommendation framework, Citta. The framework is designed with the BERT language model. It is designed to retrieve semantically related reading recommendations with short input queries and shorter response times. We test the proposed framework on the CMU Book Summary Dataset and discuss the observed advantages and shortcomings of the framework.","tags":["NLP","Information Retrieval"],"title":"Citta: A Lite Semantic Recommendation Framework for Digital Libraries","type":"publication"},{"authors":["Ajay Subramanian","Rajaswa Patil","Veeky Baths"],"categories":null,"content":"","date":1576089000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576089000,"objectID":"e60e9dd094f8f8cd0fe3294c4ae4a18f","permalink":"https://rajaswa.github.io/publication/accs-word2brain2image-2019/","publishdate":"2019-12-12T00:00:00+05:30","relpermalink":"/publication/accs-word2brain2image-2019/","section":"publication","summary":"Recent work in cognitive neuroscience has aimed to better understand how the brain responds to external stimuli. Extensive study is being done to gauge the involvement of various regions of the brain in the processing of external stimuli. A study by Ostarek et al. has produced experimental evidence of the involvement of low-level visual representations in spoken word processing, using Continuous Flash Suppression (CFS). For example, hearing the word ‚Äòcar‚Äô induces a visual representation of a car in extrastriate areas of the visual cortex that seems to have a spatial resolution of some kind. Though the structure of these areas of the brain has been extensively studied, research hasn‚Äôt really delved into the functional aspects. In this work, we aim to take this a step further by experimenting with generative models such as Variational Autoencoders (VAEs) (Kingma et al 2013) and Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) to generate images purely from the EEG signals induced by listening to spoken words of objects.","tags":["Cognitive Science","Neuroscience"],"title":"Word2Brain2Image: Visual Reconstruction from Spoken Word Representations","type":"publication"}]