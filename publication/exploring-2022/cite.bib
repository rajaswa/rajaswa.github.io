@InProceedings{pmlr-v203-patil23a,
  title = 	 {Exploring Dimensions of Generalizability and Few-shot Transfer for Text-to-SQL Semantic Parsing},
  author =       {Patil, Rajaswa and Patwardhan, Manasi and Karande, Shirish and Vig, Lovekesh and Shroff, Gautam},
  booktitle = 	 {Proceedings of The 1st Transfer Learning for Natural Language Processing Workshop},
  pages = 	 {103--114},
  year = 	 {2023},
  editor = 	 {Albalak, Alon and Zhou, Chunting and Raffel, Colin and Ramachandran, Deepak and Ruder, Sebastian and Ma, Xuezhe},
  volume = 	 {203},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {03 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v203/patil23a/patil23a.pdf},
  url = 	 {https://proceedings.mlr.press/v203/patil23a.html},
  abstract = 	 {Existing work on generalization in Text-to-SQL semantic parsing has been restricted to a zero-shot cross-domain setting. In this paper, we introduce Spider-Gen: a Text-to-SQL benchmark to develop a paradigm of transfer learning across distinct dimensions of generalization in Text-to-SQL semantic parsing. The Spider-Gen benchmark focuses on few-shot adaption for Cross-domain, Lexical, and Structural generalization of Text-to-SQL models. Through our experiments with the Spider-Gen dataset, we show that Seq2Seq language models struggle to generalize against change in data distribution, lexical changes in database schema, and changes in SQL query complexity. Our experiments also reveal that performing few-shot fine-tuning helps Text-to-SQL models to generalize across these changes. However, such few-shot adaptation comes with a negative effect on the knowledge learnt during training. Hence, we also explore Parameter-efficient Fine-tuning methods to overcome the limitations of Seq2Seq Text-to-SQL models. We release the Spider-Gen dataset publicly to facilitate further research in generalization and transfer learning across various dimensions in Text-to-SQL semantic parsing.}
}
